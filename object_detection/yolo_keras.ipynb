{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leochen/Developer/senior-design/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 640, 640, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leochen/Developer/senior-design/.venv/lib/python3.11/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'images': 'images'}\n",
      "Received: inputs=Tensor(shape=(2, 640, 640, 3))\n",
      "  warnings.warn(msg)\n",
      "/Users/leochen/Developer/senior-design/.venv/lib/python3.11/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(2, 640, 640, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'box': <tf.Tensor: shape=(2, 76725, 4), dtype=float32, numpy=\n",
      "array([[[ 1.9797763e-01, -2.9957563e-01, -9.0714228e-01, -4.6442947e-01],\n",
      "        [-1.4687498e-01, -2.7938873e-01, -6.4830250e-01, -7.0906401e-01],\n",
      "        [-2.6927525e-01,  6.3591823e-02, -6.9865471e-01, -4.0760756e-01],\n",
      "        ...,\n",
      "        [ 3.1109664e-01,  1.2415936e-03, -1.2744868e+00, -6.4395690e-01],\n",
      "        [ 2.2383158e-01, -2.2934729e-02, -7.1615052e-01, -9.4797170e-01],\n",
      "        [ 5.3185340e-02,  2.1823920e-01, -1.9512793e-01, -1.2678156e+00]],\n",
      "\n",
      "       [[-1.9693016e-01, -6.9244343e-01, -7.4605477e-01, -5.4343200e-01],\n",
      "        [-1.5767342e-01, -7.7151960e-01, -1.8343803e-01, -8.1742901e-01],\n",
      "        [-3.8995659e-01, -7.6796722e-01, -2.3006898e-01, -1.0295928e+00],\n",
      "        ...,\n",
      "        [ 1.5655182e-01, -7.2948492e-01, -1.0093043e+00, -1.1544492e+00],\n",
      "        [-4.0744662e-02, -3.6284256e-01, -4.8590446e-01, -1.1786525e+00],\n",
      "        [-1.3696626e-01,  5.8373511e-03, -1.1443286e-01, -1.3269767e+00]]],\n",
      "      dtype=float32)>, 'classification': <tf.Tensor: shape=(2, 76725, 20), dtype=float32, numpy=\n",
      "array([[[-5.1917105, -4.6348476, -4.8738303, ..., -4.627208 ,\n",
      "         -4.9447575, -5.139815 ],\n",
      "        [-4.9926476, -5.0965686, -4.8245597, ..., -4.7004185,\n",
      "         -4.821479 , -5.2421637],\n",
      "        [-4.707704 , -5.020277 , -4.67198  , ..., -4.596635 ,\n",
      "         -4.35189  , -5.030463 ],\n",
      "        ...,\n",
      "        [-5.4379826, -4.617598 , -4.7377405, ..., -4.2574863,\n",
      "         -4.5940194, -4.8536015],\n",
      "        [-5.3379984, -4.812303 , -4.7366004, ..., -4.2676187,\n",
      "         -4.6184597, -4.7829313],\n",
      "        [-5.666168 , -4.633464 , -5.626241 , ..., -4.470447 ,\n",
      "         -5.566108 , -5.424636 ]],\n",
      "\n",
      "       [[-6.3737106, -5.7320013, -5.515173 , ..., -5.083649 ,\n",
      "         -6.575492 , -5.747297 ],\n",
      "        [-6.1306543, -6.145226 , -5.515853 , ..., -5.3407574,\n",
      "         -6.0387764, -5.9285994],\n",
      "        [-5.4283795, -5.8958874, -5.462919 , ..., -5.497941 ,\n",
      "         -5.4831877, -5.643632 ],\n",
      "        ...,\n",
      "        [-4.2333326, -4.4136925, -4.456873 , ..., -4.683239 ,\n",
      "         -3.740162 , -4.434917 ],\n",
      "        [-3.845723 , -4.3123145, -5.4450216, ..., -4.0426474,\n",
      "         -3.5226676, -3.99619  ],\n",
      "        [-3.9906378, -4.31697  , -5.5795903, ..., -4.0736856,\n",
      "         -4.3305116, -4.9145164]]], dtype=float32)>}\n",
      "(2, 76725, 4)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'num_detections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(keras\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mshape(predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_detections\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m class_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAeroplanes\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBicycles\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTV/Monitors\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_detections'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_cv\n",
    "# import tensorflow as tf\n",
    "\n",
    "model = keras_cv.models.RetinaNet.from_preset(\n",
    "    preset='retinanet_resnet50_pascalvoc',\n",
    "    load_weights=True,\n",
    "    num_classes=20,\n",
    "    bounding_box_format='XYWH'\n",
    ")\n",
    "\n",
    "image1 = keras.utils.load_img(\n",
    "    path='test.jpg',\n",
    "    color_mode='rgb',\n",
    "    target_size=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False,\n",
    ")\n",
    "image1 = keras.utils.img_to_array(image1)\n",
    "image1 = keras.layers.Resizing(640, 640)(image1)\n",
    "image1 = keras.ops.reshape(x=image1, newshape=(1, *image1.shape))\n",
    "\n",
    "image2 = keras.utils.load_img(\n",
    "    path='people.jpg',\n",
    "    color_mode='rgb',\n",
    "    target_size=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False,\n",
    ")\n",
    "image2 = keras.utils.img_to_array(image2)\n",
    "image2 = keras.layers.Resizing(640, 640)(image2)\n",
    "image2 = keras.ops.reshape(x=image2, newshape=(1, *image2.shape))\n",
    "\n",
    "images = keras.ops.concatenate(xs=[image1, image2], axis=0)\n",
    "# images = keras.ops.reshape(x=images, newshape=(1, *images.shape))\n",
    "print(images.shape)\n",
    "\n",
    "\n",
    "predictions: dict = model(images)\n",
    "print(predictions)\n",
    "print(keras.ops.shape(predictions['box']))\n",
    "for each in predictions['num_detections']:\n",
    "    print(f'number of predictions: {each}')\n",
    "\n",
    "class_ids = [\n",
    "    'Aeroplanes',\n",
    "    'Bicycles',\n",
    "    'Birds',\n",
    "    'Boats',\n",
    "    'Bottles',\n",
    "    'Buses',\n",
    "    'Cars',\n",
    "    'Cats',\n",
    "    'Chairs',\n",
    "    'Cows',\n",
    "    'Dining tables',\n",
    "    'Dogs',\n",
    "    'Horses',\n",
    "    'Motorbikes',\n",
    "    'People',\n",
    "    'Potted plants',\n",
    "    'Sheep',\n",
    "    'Sofas',\n",
    "    'Trains',\n",
    "    'TV/Monitors'\n",
    "]\n",
    "\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "# y_pred = keras_cv.bounding_box.to_ragged(y_pred)\n",
    "keras_cv.visualization.plot_bounding_box_gallery(\n",
    "    images,\n",
    "    value_range=(0, 255),\n",
    "    bounding_box_format='XYWH',\n",
    "    y_true=None,\n",
    "    y_pred=predictions,\n",
    "    scale=4,\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    show=True,\n",
    "    font_scale=0.5,\n",
    "    class_mapping=class_mapping,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
